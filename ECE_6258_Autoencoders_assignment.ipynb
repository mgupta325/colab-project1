{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE_6258_Autoencoders_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgupta325/colab-project1/blob/master/ECE_6258_Autoencoders_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKVxDV1Icw0J",
        "colab_type": "text"
      },
      "source": [
        "**The ECE 6258 assingment for autoencoders**\n",
        "\n",
        "\n",
        "\n",
        "*   shallower network\n",
        "*   reconstruction(fc nonlinear , fc linear, sparse, denoise)\n",
        "*   denoise (3 level)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzVvFvc1zJun",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3vHOgxMzJWu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P5SpOqH5NZz",
        "colab_type": "code",
        "outputId": "3e8290c7-2864-492e-97b8-6e2cd3d4cd48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "#0\n",
        "print(torch.cuda.device_count())\n",
        "#1\n",
        "print(torch.cuda.get_device_name(0))\n",
        "#Tesla K80\n",
        "print(torch.cuda.is_available())\n",
        "#True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "Tesla K80\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKflJE57p4pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### importing python packages ######\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import gzip\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import cv2\n",
        "# make dir to save images\n",
        "if not os.path.exists('./in_out_img'):\n",
        "    os.mkdir('./in_out_img')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoGunxGoqU3-",
        "colab_type": "text"
      },
      "source": [
        "**training configs (user defined)**      \n",
        "**please adjust the training hyperparameters and architectures in this part**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_M5rFSIwHW",
        "colab_type": "text"
      },
      "source": [
        "**models (nonlinear_AE  |  linear_AE  |  sparse_AE| conv_AE | denoise_AE | )** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUq0sMF-J2hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the non-linear autoencoder  \n",
        "class nonlinear_AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(nonlinear_AE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.ReLU(True),)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 28 * 28), \n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# define the linear autoencoder \n",
        "class linear_AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(linear_AE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 28 * 28), \n",
        "            )\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "#define the sparse autoencoder\n",
        "class sparse_AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(sparse_AE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        " \n",
        "# define the convolutional autoencoder  16 -- 8 -- 16 -- 1  # the conv2d + unpooling implementation\n",
        "class conv_AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(conv_AE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),   # single channel grayscale images  \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )  ## latent features has dimention of N, 8, 7, 7\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # the Transposed Convolutions in decoder layers\n",
        "            # output_size = stride*(input-1)+kernel_size-2*padding\n",
        "            nn.ConvTranspose2d(8, 16, 2, stride=2),  #2x (7-1) + 2 = 14\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(16, 1, 2, stride=2),    # 2x(14-1)+2 = 28\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "\n",
        "def sparse_loss(autoencoder, inputs):\n",
        "    loss = 0\n",
        "    out = inputs\n",
        "    fc_layer = list(autoencoder.encoder.children())[0]\n",
        "    relu = list(autoencoder.encoder.children())[1]\n",
        "    out = relu(fc_layer(out))\n",
        "    loss += kl_divergence(sparsity_parameter, out)\n",
        "    return loss\n",
        "\n",
        "def kl_divergence(p, p_hat):\n",
        "    funcs = nn.Sigmoid()\n",
        "    p_hat = torch.mean(funcs(p_hat), 1)\n",
        "    p_tensor = torch.Tensor([p] * len(p_hat)).cuda()\n",
        "    return torch.sum(p_tensor * torch.log(p_tensor) - p_tensor * torch.log(p_hat) + (1 - p_tensor) * torch.log(1 - p_tensor) - (1 - p_tensor) * torch.log(1 - p_hat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSxbv1AT_YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Choosing model\n",
        "arch = 'linear_AE'   # 'nonlinear_AE' | 'linear_AE' | 'sparse_AE' | 'conv_AE' | 'denoise_AE' | "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1EAHDP6ZCi1",
        "colab_type": "text"
      },
      "source": [
        "**load model**\n",
        "1. Upload the provided 5 models\n",
        "2.run the cell below to load the model based on the arch you choose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6X5-Hd6YoMs",
        "colab_type": "code",
        "outputId": "5de94e22-5762-4dc9-faf8-e40e30c3d23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model_state_dict = torch.load('./' + arch + '_best.pth')\n",
        "\n",
        "if arch == 'nonlinear_AE':  \n",
        "    model = nonlinear_AE().cuda()\n",
        "elif arch == 'linear_AE':\n",
        "    model = linear_AE().cuda()\n",
        "elif arch == 'sparse_AE':\n",
        "    model = sparse_AE().cuda()\n",
        "elif arch == 'conv_AE':\n",
        "    model = conv_AE().cuda()\n",
        "elif arch == 'denoise_AE':\n",
        "    model = nonlinear_AE().cuda()\n",
        "\n",
        "model.load_state_dict(model_state_dict)\n",
        "print(model)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nonlinear_AE(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=784, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqWALpQu5wFM",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STExRatMcStL",
        "colab_type": "text"
      },
      "source": [
        "**upload your own local image file to notebook directory**    \n",
        "everytime you restart notebook, you need to upload local files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkGcsq-YQpMo",
        "colab_type": "code",
        "outputId": "7e5ed41e-3b5c-4c94-d193-64d866eaf9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = MNIST('./data', train=True, download=True,transform=None)\n",
        "# fix random seed for reproducible results\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "# \n",
        "# define the transformation applied to MNIST images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# train/test loader \n",
        "train_loader = DataLoader(MNIST('./data', train=True, download=True, \n",
        "                          transform=transform),  shuffle=True)\n",
        "test_loader = DataLoader(MNIST('./data', train=False, \n",
        "                          transform=transform), shuffle=False)\n",
        "filename = [\n",
        "[\"training_images\",\"./data/MNIST/raw/train-images-idx3-ubyte.gz\"],\n",
        "[\"test_images\",\"./data/MNIST/raw/t10k-images-idx3-ubyte.gz\"],\n",
        "[\"training_labels\",\"./data/MNIST/raw/train-labels-idx1-ubyte.gz\"],\n",
        "[\"test_labels\",\"./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\"]\n",
        "]\n",
        "\n",
        "# load downloaded .gz files to and save images as numpy arrays \n",
        "def save_mnist():\n",
        "    mnist = {}\n",
        "    for name in filename[:2]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
        "    # for name in filename[-2:]:\n",
        "    #     with gzip.open(name[1], 'rb') as f:\n",
        "    #         mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    with open(\"mnist.pkl\", 'wb') as f:\n",
        "        pickle.dump(mnist,f)\n",
        "    print(\"Save complete.\")\n",
        "\n",
        "save_mnist()\n",
        "\n",
        "with open(\"mnist.pkl\",'rb') as f:\n",
        "    mnist = pickle.load(f)\n",
        "    mnist_train_X = mnist[\"training_images\"]  # 60000, 784\n",
        "    mnist_test_X = mnist[\"test_images\"]  # 10000, 784\n",
        "\n",
        "# TODO:\n",
        "##1.use your own image and resize it to (28,28) as test image 1\n",
        "##2.define idx[0,9999] to pick one test image from mnist as test image 2\n",
        "\n",
        "##enter your image path here(you have to upload it first)\n",
        "img = Image.open('/content/airplane_downsample_gray_square.jpg') ##You can change this\n",
        "test_img_1 = np.array(img.resize((28,28)))\n",
        "##choose an idx here\n",
        "idx = 0 ##You can change this\n",
        "test_img_2 = mnist_test_X[idx].reshape(28,28)  / 255.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl7u4SVSchOF",
        "colab_type": "code",
        "outputId": "c1864a4b-22d3-48f8-a818-0dfb28583850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#TODO: define a noise ratio to evaluate the denoise autoencoder[0.1,0.4,0.9]\n",
        "noise_ratio = 0.5\n",
        "def evaluate(model, img):\n",
        "    recons_loss = nn.MSELoss()\n",
        "    model.eval()\n",
        "    if arch != 'conv_AE':\n",
        "            # TODO: 1 1 784\n",
        "            img = torch.from_numpy(img.reshape(1,1,784)).float().cuda()\n",
        "          \n",
        "            print(img.shape)\n",
        "\n",
        "    elif arch == 'denoise_AE':\n",
        "            noise_img = img * (1 - noise_ratio) + torch.rand(img.size()) * noise_ratio      # add noise onto input images\n",
        "            noise_img = Variable(noise_img.cuda())\n",
        "            img = Variable(img.cuda())\n",
        "            out = model(noise_img)\n",
        "    else:\n",
        "         img = Variable(torch.from_numpy(img.reshape(1,1,28,28)).float().cuda())\n",
        "    out = model(img.cuda())\n",
        "            \n",
        "    loss = recons_loss(out, img)\n",
        "    \n",
        "    return loss\n",
        "  \n",
        "if arch != 'denoise_AE':\n",
        "  MSEloss_1 = evaluate(model,test_img_1)\n",
        "  MSEloss_2 = evaluate(model,test_img_2)\n",
        "  print(\"loss for test_img1 = \",MSEloss_1)\n",
        "  print(\"loss for test_img2 = \",MSEloss_2)\n",
        "else:\n",
        "  plt.figure()\n",
        "  plt.imshow(test_img_2, cmap='gray')\n",
        "  plt.axis('off')\n",
        "  Image.fromarray(test_img_2).convert(\"L\").save(\"clean_input.jpg\")\n",
        "  plt.savefig('clean_input.png')\n",
        "\n",
        "  noise = torch.rand(torch.Size([28, 28])).numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(noise,cmap='gray')\n",
        "  plt.axis('off')\n",
        "  Image.fromarray(noise).convert(\"L\").save(\"rand_noise.jpg\")\n",
        "  plt.savefig('rand_noise.png')\n",
        "\n",
        "  corrupt_img =test_img_2 * (1 - noise_ratio) + noise * noise_ratio \n",
        "  plt.figure()\n",
        "  plt.imshow(corrupt_img,cmap='gray')\n",
        "  plt.axis('off')\n",
        "  Image.fromarray(corrupt_img).convert(\"L\").save(\"corrupt_input.jpg\")\n",
        "  plt.savefig('corrupt_input.png')\n",
        "    \n",
        "\n",
        "  img = torch.from_numpy(test_img_2.reshape(1,1,784)).float()\n",
        "  noise_img =  img * (1 - noise_ratio) + torch.from_numpy(noise.reshape(1,1,784))*noise_ratio \n",
        "  out = model(noise_img.cuda()).view(28,28).cpu().detach().numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(out,cmap='gray')\n",
        "  plt.axis('off')\n",
        "  Image.fromarray(corrupt_img).convert(\"L\").save(\"denoised_output.jpg\")\n",
        "  plt.savefig('denoised_output.png')\n",
        "  \n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 784])\n",
            "torch.Size([1, 1, 784])\n",
            "loss for test_img1 =  tensor(22393.8730, device='cuda:0', grad_fn=<MseLossBackward>)\n",
            "loss for test_img2 =  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y-tU3sODuO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbOpspYT2RjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}